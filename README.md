# Parrot

This project provides **automatic translation between Korean and Japanese** using Facebook's M2M or NLLB models.

## Key Features

- Supports bidirectional translation: Korean â†’ Japanese and Japanese â†’ Korean
- Built on the Hugging Face Transformers library
- Utilizes large pre-trained AI translation models (M2M, NLLB, etc.)
- Smart terminology processing:
  - Retrieval-Augmented Generation (RAG) for CausalLM models
  - Preprocessing-based replacement for Seq2SeqLM models
- Redis caching for optimized response times

### Setup

Getting a Hugging Face Access Token (Read)

https://huggingface.co/docs/hub/security-tokens

```
.env

HUGGINGFACE_HUB_TOKEN=value
```

### Install

```bash
poetry install
```

### Download Model

```bash
poetry run python scripts/download_models.py --model nllb-200
poetry run python scripts/download_models.py --model m2m-100-1.2b
poetry run python scripts/download_models.py --model qwen2.5-1.5b
poetry run python scripts/download_models.py --model hyperclova-1.5b
poetry run python scripts/download_models.py --model varco-8b
```

### Translate

```bash
poetry run python scripts/test.py --translate "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”." ko2ja --model nllb-200
poetry run python scripts/test.py --translate "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”." ko2ja --model m2m-100-1.2b
poetry run python scripts/test.py --translate "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”." ko2ja --model qwen2.5-1.5b
poetry run python scripts/test.py --translate "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”." ko2ja --model hyperclova-1.5b
poetry run python scripts/test.py --translate "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”." ko2ja --model varco-8b
poetry run python scripts/test.py --translate "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤." ko2ja --model nllb-200
poetry run python scripts/test.py --translate "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤." ko2ja --model m2m-100-1.2b
poetry run python scripts/test.py --translate "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤." ko2ja --model qwen2.5-1.5b
poetry run python scripts/test.py --translate "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤." ko2ja --model hyperclova-1.5b
poetry run python scripts/test.py --translate "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤." ko2ja --model varco-8b
```

### Model Performance

```bash
poetry run python scripts/test.py --performance --model nllb-200
poetry run python scripts/test.py --performance --model m2m-100-1.2b
```

Example
```
ğŸš€ Performance Test
==================================================
ğŸ“¥ Testing model: m2m-100-1.2b
Loading model (seq2seqlm): facebook/m2m100_1.2B
Using device: mps
âœ“ Tokenizer loaded
âœ“ Model loaded successfully.
âœ“ FAISS loaded successfully.
âœ“ Terminology database loaded: 12 terms

ğŸ“Š Performance Results:
------------------------------
âœ“ Translating from 'ko' to 'ja'...
ğŸ¯ ì§§ì€ ë¬¸ì¥:
  Input: ì•ˆë…•
  Output: ãŠã¯ã‚ˆã†
  Time: 0.800s
  Speed: 2.5 chars/sec

âœ“ Translating from 'ko' to 'ja'...
ğŸ¯ ì¤‘ê°„ ë¬¸ì¥:
  Input: ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”
  Output: ä»Šæ—¥ã¯å¤©æ°—ã„ã„ã­ã€‚
  Time: 1.096s
  Speed: 11.9 chars/sec

âœ“ Translating from 'ko' to 'ja'...
ğŸ¯ ê¸´ ë¬¸ì¥:
  Input: íŒŒì´ì¬ì„ ì‚¬ìš©í•´ì„œ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ë¡œ í•œêµ­ì–´ì™€ ì¼ë³¸ì–´ ë²ˆì—­ê¸°ë¥¼ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤
  Output: Pythonã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒƒã‚­ãƒ³ã‚°ãƒ•ã‚§ã‚¤ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦éŸ“å›½èªã¨æ—¥æœ¬èªã®ç¿»è¨³æ©Ÿã‚’ä½œã£ã¦ã„ã¾ã™
  Time: 1.791s
  Speed: 23.5 chars/sec

âœ“ Translating from 'ko' to 'ja'...
ğŸ¯ ë³µì¡í•œ ë¬¸ì¥:
  Input: ì €ëŠ” ì„œìš¸ì— ì‚´ê³  ìˆëŠ” ëŒ€í•™ìƒì´ë©°, ì¸ê³µì§€ëŠ¥ê³¼ ìì—°ì–´ ì²˜ë¦¬ì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤
  Output: ç§ã¯ã‚½ã‚¦ãƒ«ã«ä½ã‚€å¤§å­¦ç”Ÿã§ã€äººå·¥çŸ¥èƒ½ã¨è‡ªç„¶è¨€èªå‡¦ç†ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™ã€‚
  Time: 1.442s
  Speed: 29.1 chars/sec

ğŸ“ˆ Overall Performance:
  Total time: 5.128s
  Total characters: 99
  Average speed: 19.3 chars/sec
```

### Model Info

```bash
poetry run python scripts/test.py --info --model nllb-200
poetry run python scripts/test.py --info --model m2m-100-1.2b
```

Example
```
Loading model (seq2seqlm): facebook/m2m100_1.2B
Using device: mps
âœ“ Tokenizer loaded
âœ“ Model loaded successfully.
âœ“ FAISS loaded successfully.
âœ“ Terminology database loaded: 12 terms
â„¹ï¸  Translation Model Information
==================================================
Model: facebook/m2m100_1.2B
Device: mps
Languages: korean, japanese, english
Directions: Korean â†’ Japanese, Japanese â†’ Korean
==================================================

ğŸ“‹ Available Models:
nllb-200: {'name': 'facebook/nllb-200-distilled-600M', 'transformer': 'seq2seqlm'}
m2m-100-1.2b: {'name': 'facebook/m2m100_1.2B', 'transformer': 'seq2seqlm'}
...
```

### Benchmark Models

```bash
poetry run python scripts/test.py --benchmark
```

Example
```
âš¡ Model Benchmark
==================================================

ğŸ” Testing: nllb-200
----------------------------------------
Loading model (seq2seqlm): facebook/nllb-200-distilled-600M
Using device: mps
âœ“ Tokenizer loaded
âœ“ Model loaded successfully.
âœ“ FAISS loaded successfully.
âœ“ Terminology database loaded: 12 terms
âœ“ Translating from 'kor_Hang' to 'jpn_Jpan'...
ğŸ‡°ğŸ‡· Korean: ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.
âœ“ Translation completed: ã“ã‚“ã«ã¡ã¯. ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™
â±ï¸  Load: 7.97s, Translate: 1.31s

âœ“ Translating from 'jpn_Jpan' to 'kor_Hang'...
ğŸ‡¯ğŸ‡µ Japanese: ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚
âœ“ Translation completed: ì•ˆë…•, ì•ˆë…•. ì˜¤ëŠ˜ ì¢‹ì€ ë‚ ì”¨ì…ë‹ˆë‹¤.
â±ï¸  Load: 7.97s, Translate: 0.63s


ğŸ” Testing: m2m-100-1.2b
----------------------------------------
Loading model (seq2seqlm): facebook/m2m100_1.2B
Using device: mps
âœ“ Tokenizer loaded
âœ“ Model loaded successfully.
âœ“ Terminology database loaded: 12 terms
âœ“ Translating from 'ko' to 'ja'...
ğŸ‡°ğŸ‡· Korean: ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.
âœ“ Translation completed: ã“ã‚“ã«ã¡ã¯!ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã€‚
â±ï¸  Load: 8.29s, Translate: 0.99s

âœ“ Translating from 'ja' to 'ko'...
ğŸ‡¯ğŸ‡µ Japanese: ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã¯ã„ã„å¤©æ°—ã§ã™ã­ã€‚
âœ“ Translation completed: ì•ˆë…•í•˜ì„¸ìš” ì˜¤ëŠ˜ì€ ì¢‹ì€ ë‚ ì”¨ì…ë‹ˆë‹¤.
â±ï¸  Load: 8.29s, Translate: 0.65s


ğŸ“Š Benchmark Summary:
==================================================
nllb-200 (ko2ja): Load 7.97s, Translate 1.31s
nllb-200 (ja2ko): Load 7.97s, Translate 0.63s
m2m-100-1.2b (ko2ja): Load 8.29s, Translate 0.99s
m2m-100-1.2b (ja2ko): Load 8.29s, Translate 0.65s
...
```

### API

```bash
poe dev - ê°œë°œ ì„œë²„ (ìë™ ì¬ì‹œì‘)
poe start - ì¼ë°˜ ì„œë²„
poe prod - í”„ë¡œë•ì…˜ ì„œë²„ (ë©€í‹° ì›Œì»¤)
```

### Testing

#### Environment Information
- **Hardware**: Macbook M3
- **Model**: m2m-100-1.2b
- **Description**: `Text2Text Generation` A task that takes input text and transforms it into a different form of text.

Request:
```bash
curl -G "http://localhost:8000/translate/ko2ja" \
  --data-urlencode "text=ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”" \
  --data-urlencode "model=m2m-100-1.2b" | jq
```

Response:
```json
{
  "original": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”",
  "translated": "ã“ã‚“ã«ã¡ã¯! ä»Šæ—¥ã®å¤©æ°—ã¯ã¨ã¦ã‚‚è‰¯ã„ã§ã™ã€‚",
  "translate_time": "0.98s"
}
```

Request:
```bash
curl -G "http://localhost:8000/translate/ko2ja" \
  --data-urlencode "text=ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤."\
  --data-urlencode "model=m2m-100-1.2b" | jq
```

Response:
```json
{
  "original": "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤.",
  "translated": "ã‚¸ã‚§ã‚¤ãƒŸã‚·ãƒ§ãƒƒãƒ—ãƒã‚«ãƒ»ã‚°ãƒƒã‚ºä¸€æ‹¬ä¾¡æ ¼ã‚‚è²©å£²ã—ã¦ã„ã¾ã™ã€‚",
  "translate_time": "1.64s"
}
```

#### Environment Information
- **Hardware**: Macbook M3
- **Model**: hyperclova-1.5b
- **Description**: `Safetensors` A new file format for storing machine learning model weights.

Request:
```bash
curl -G "http://localhost:8000/translate/ko2ja" \
  --data-urlencode "text=ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ ê°€ ì •ë§ ì¢‹ë„¤ìš”" \
  --data-urlencode "model=hyperclova-1.5b" | jq
```

Response:
```json
{
  "original": "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”",
  "translated": "ã“ã‚“ã«ã¡ã¯ã€‚ä»Šæ—¥ã®å¤©æ°—ãŒæœ¬å½“ã«å¥½ã„ã§ã™ã€‚",
  "translate_time": "0.89s"
}
```

Request:
```bash
curl -G "http://localhost:8000/translate/ko2ja" \
  --data-urlencode "text=ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤."\
  --data-urlencode "model=hyperclova-1.5b" | jq
```

Response:
```json
{
  "original": "ì¬ì´ë¯¸ìƒµ í¬ì¹´ êµ¿ì¦ˆ ì¼ê´„ ì›ê°€ ì–‘ë„ íŒë§¤í•©ë‹ˆë‹¤.",
  "translated": "ã‚¸ãƒ£ã‚¤ãƒŸã‚·ãƒ¼ã®ãƒã‚«ã‚°ãƒƒãƒ‰ä¸€ç·’ã« ì›ê°€ë¥¼ ì–‘ë„í•©ë‹ˆë‹¤ã€‚",
  "translate_time": "2.94s"
}
```